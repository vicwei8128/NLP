{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification  \n",
    "`pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                sms  target\n",
      "0   ham  Go until jurong point, crazy.. Available only ...       0\n",
      "1   ham                      Ok lar... Joking wif u oni...       0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
      "3   ham  U dun say so early hor... U c already then say...       0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('./dataset/spam.csv')\n",
    "df['target'] = df['label'].map( {'spam':1, 'ham':0 })\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'\n",
      " 'Ok lar... Joking wif u oni...'\n",
      " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "text_train = np.asarray(df['sms'])\n",
    "y_train = np.asarray(df['target'])\n",
    "print(text_train[:3])\n",
    "print(y_train[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 1602)\n",
      "(5572,)\n",
      "[0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words=\"english\", min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\Python_Course\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               820736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 985,218\n",
      "Trainable params: 985,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(1602,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "             loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3900 samples, validate on 1672 samples\n",
      "Epoch 1/10\n",
      "3900/3900 - 1s - loss: 0.2241 - acc: 0.9233 - val_loss: 0.0541 - val_acc: 0.9827\n",
      "Epoch 2/10\n",
      "3900/3900 - 1s - loss: 0.0290 - acc: 0.9923 - val_loss: 0.0555 - val_acc: 0.9833\n",
      "Epoch 3/10\n",
      "3900/3900 - 0s - loss: 0.0060 - acc: 0.9987 - val_loss: 0.0744 - val_acc: 0.9839\n",
      "Epoch 4/10\n",
      "3900/3900 - 0s - loss: 0.0036 - acc: 0.9995 - val_loss: 0.0729 - val_acc: 0.9839\n",
      "Epoch 5/10\n",
      "3900/3900 - 0s - loss: 0.0034 - acc: 0.9995 - val_loss: 0.0771 - val_acc: 0.9839\n",
      "Epoch 6/10\n",
      "3900/3900 - 0s - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0796 - val_acc: 0.9839\n",
      "Epoch 7/10\n",
      "3900/3900 - 1s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0908 - val_acc: 0.9844\n",
      "Epoch 8/10\n",
      "3900/3900 - 1s - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0836 - val_acc: 0.9839\n",
      "Epoch 9/10\n",
      "3900/3900 - 0s - loss: 0.0031 - acc: 0.9995 - val_loss: 0.1049 - val_acc: 0.9839\n",
      "Epoch 10/10\n",
      "3900/3900 - 0s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0973 - val_acc: 0.9844\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test = ['Hi Paul, would you come around tonight']\n",
    "\n",
    "test_str  = vect.transform(sms_test)\n",
    "\n",
    "model.predict_classes(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_test = ['Free SMS service for anyone']\n",
    "test_str  = vect.transform(sms_test)\n",
    "\n",
    "model.predict_classes(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
